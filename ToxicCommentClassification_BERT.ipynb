{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ToxicCommentClassification_BERT.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxFagI9XQRbU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99b9e988-9bef-4179-894e-152b66ced1f1"
      },
      "source": [
        "!pip install sentence-transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sentence-transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/35/aa/f672ce489063c4ee7a566ebac1b723c53ac0cea19d9e36599cc241d8ed56/sentence-transformers-1.0.4.tar.gz (74kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 6.1MB/s \n",
            "\u001b[?25hCollecting transformers<5.0.0,>=3.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d8/b2/57495b5309f09fa501866e225c84532d1fd89536ea62406b2181933fb418/transformers-4.5.1-py3-none-any.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 22.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (4.41.1)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.8.1+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.4.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (3.2.5)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 39.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (3.10.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (20.9)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/08/cd/342e584ee544d044fb573ae697404ce22ede086c9e87ce5960772084cad0/sacremoses-0.0.44.tar.gz (862kB)\n",
            "\u001b[K     |████████████████████████████████| 870kB 38.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (2019.12.20)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/04/5b870f26a858552025a62f1649c20d29d2672c02ff3c3fb4c688ca46467a/tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 43.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (3.0.12)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->sentence-transformers) (3.7.4.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sentence-transformers) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk->sentence-transformers) (1.15.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers<5.0.0,>=3.1.0->sentence-transformers) (3.4.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers<5.0.0,>=3.1.0->sentence-transformers) (2.4.7)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=3.1.0->sentence-transformers) (7.1.2)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (3.0.4)\n",
            "Building wheels for collected packages: sentence-transformers, sacremoses\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-1.0.4-cp37-none-any.whl size=114307 sha256=d14b8728047957e2bf1880fee662ba6f36af1028861de800701570927056b16c\n",
            "  Stored in directory: /root/.cache/pip/wheels/26/ea/89/d0d2e013d951b6d23270aa9ca4018b82632ab7cd933c331316\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.44-cp37-none-any.whl size=886084 sha256=5578efac018174b076bc5b7ab686820611252097219c100a26c49fb61b6381c9\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/fb/c0/13ab4d63d537658f448366744654323077c4d90069b6512f3c\n",
            "Successfully built sentence-transformers sacremoses\n",
            "Installing collected packages: sacremoses, tokenizers, transformers, sentencepiece, sentence-transformers\n",
            "Successfully installed sacremoses-0.0.44 sentence-transformers-1.0.4 sentencepiece-0.1.95 tokenizers-0.10.2 transformers-4.5.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbFoKO3aNwEt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af7191c2-3fc0-4277-c1dc-d7e954afcd85"
      },
      "source": [
        "# import necessary files\n",
        "import pandas as pd\n",
        "# import seaborn as sns\n",
        "import numpy as np\n",
        "# import spacy\n",
        "# import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, classification_report, precision_recall_curve, average_precision_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import svm\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import time\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import RegexpTokenizer \n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from keras.preprocessing import text, sequence\n",
        "from keras import regularizers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout, Flatten\n",
        "from keras.layers import Embedding, Conv1D, MaxPooling1D, GlobalMaxPooling1D \n",
        "from keras.utils import plot_model\n",
        "from keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import pickle\n",
        "from sentence_transformers import SentenceTransformer"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-fe_l7ENKkK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e9d0b63-329e-4f49-92c8-b2feb81ca682"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUfyAtI4FZND"
      },
      "source": [
        "# data cleaning method: removes http links, special characters and user tagged comments \n",
        "def clean_data(text):\n",
        "  text = text.map(lambda x: re.sub('\\\\n',' ',str(x)))\n",
        "  text = text.map(lambda x: re.sub(\"\\[\\[User.*\",'',str(x)))\n",
        "  text = text.map(lambda x: re.sub(\"\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\",'',str(x)))\n",
        "  text = text.map(lambda x: re.sub(\"(http://.*?\\s)|(http://.*)\",'',str(x)))\n",
        "  return text\n",
        "\n",
        "stopset = set(stopwords.words('english'))\n",
        "stopset.update(['.', ',', '\"', \"'\", ':', ';', '(', ')', '[', ']', '{', '}'])\n",
        "\n",
        "# Method to remove stopwords\n",
        "def remove_stopword(text):\n",
        "  tokenizer = RegexpTokenizer(r'\\w+')\n",
        "  processed = []\n",
        "  for comment in tqdm(text):\n",
        "    tokens = tokenizer.tokenize(comment)\n",
        "    word_list = [word for word in tokens if word not in stopset]\n",
        "    processed.append(\" \".join(word_list))\n",
        "  return processed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzClhUuvdKYh"
      },
      "source": [
        "To run this notebook, place the data folder into your Google Drive and change the data path below (line 2) to your data directory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AW2lYlARNTLN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "219aee9b-8fc6-4492-8bf0-1ec8791b947c"
      },
      "source": [
        "# read train and test data\n",
        "data_path = \"/content/drive/My Drive/NLP_Data/\"\n",
        "train = pd.read_csv(data_path+\"train.csv\")\n",
        "train = train.fillna('na')\n",
        "test = pd.read_csv(data_path+\"test.csv\")\n",
        "test = test.fillna('na')\n",
        "test_labels = pd.read_csv(data_path+\"test_labels.csv\")\n",
        "# print(train.columns)\n",
        "\n",
        "#remove rows from test set that have -1s\n",
        "test_with_labels = pd.concat([test, test_labels], axis = 1)\n",
        "test_with_labels = test_with_labels[test_with_labels['toxic'] != -1]\n",
        "\n",
        "#remove unnecessary columns\n",
        "X_train = train['comment_text']\n",
        "X_test = test_with_labels['comment_text']\n",
        "y_train = train[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult','identity_hate']]\n",
        "y_test = test_with_labels[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult','identity_hate']]\n",
        "\n",
        "# Cleaning the df \n",
        "clean_train = clean_data(X_train).tolist()\n",
        "clean_test = clean_data(X_test).tolist()\n",
        "\n",
        "# Removing stop words \n",
        "clean_train = remove_stopword(clean_train)\n",
        "clean_test = remove_stopword(clean_test)\n",
        "\n",
        "X_train1 = pd.DataFrame(clean_train, columns=['comment_text'])\n",
        "X_test1 = pd.DataFrame(clean_test, columns=['comment_text'])\n",
        "\n",
        "# creating a subset of each dataset in order to run relatively fast with BERT\n",
        "X_train_subset = X_train1[:2000]\n",
        "X_test_subset = X_test1[:400]\n",
        "y_train_subset = y_train[:2000]\n",
        "y_test_subset = y_test[:400]\n",
        "\n",
        "# Splitting training data into train and validation sets \n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train_subset, y_train_subset, test_size=0.2, random_state=42)\n",
        "\n",
        "# Printing lengths of train, test and validation to split after vectorization \n",
        "print(\"length of train is ...\" + str(len(X_train)))\n",
        "print(\"length of validation is ...\" + str(len(X_val)))\n",
        "print(\"length of test is ...\" + str(len(X_test_subset)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total time 4.5119030475616455\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  2%|▏         | 3940/159571 [00:00<00:03, 39396.94it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "total time 1.79317307472229\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 159571/159571 [00:04<00:00, 37094.60it/s]\n",
            "100%|██████████| 63978/63978 [00:01<00:00, 39025.72it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "length of train is ...1600\n",
            "length of validation is ...400\n",
            "length of test is ...400\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvBNTgzANAXL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c997d8a-d4c5-4f09-b00c-11a2dc347f9b"
      },
      "source": [
        "print(X_train_subset.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                        comment_text\n",
            "0  Explanation Why edits made username Hardcore M...\n",
            "1  D aww He matches background colour I seemingly...\n",
            "2  Hey man I really trying edit war It guy consta...\n",
            "3  More I make real suggestions improvement I won...\n",
            "4              You sir hero Any chance remember page\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_k0XHS2OZVXM"
      },
      "source": [
        "# Function for vectorization using BERT\n",
        "def bert_vectorize(df, model):\n",
        "    start_time=time.time()\n",
        "    sentences = df['comment_text'].tolist()\n",
        "    #load pretrained BERT model\n",
        "    #encode sentences\n",
        "    vectors = model.encode(sentences)\n",
        "    end_time=time.time()\n",
        "    print(\"total time to vectorize: \",end_time-start_time)\n",
        "    return list(vectors)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hw-2OnT5vmWm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b419e792-5e3a-474e-a9c6-b07c992892ed"
      },
      "source": [
        "# Vectorize data using BERT\n",
        "model = SentenceTransformer('bert-base-nli-stsb-mean-tokens')\n",
        "\n",
        "vectorized_X_train_subset = bert_vectorize(X_train, model)\n",
        "vectorized_X_val = bert_vectorize(X_val, model)\n",
        "vectorized_X_test = bert_vectorize(X_test_subset, model)\n",
        "\n",
        "# verifying lengths of train, test and validation after vectorization \n",
        "print(\"length of train is ...\" + str(len(vectorized_X_train_subset)))\n",
        "print(\"length of validation is ...\" + str(len(vectorized_X_val)))\n",
        "print(\"length of test is ...\" + str(len(X_test_subset)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 405M/405M [00:18<00:00, 21.7MB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "total time to vectorize:  251.22597742080688\n",
            "total time to vectorize:  64.99932622909546\n",
            "total time to vectorize:  85.3821349143982\n",
            "length of train is ...1600\n",
            "length of validation is ...400\n",
            "length of test is ...400\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWwz2QGSMFOu"
      },
      "source": [
        "# classify data: LogReg\n",
        "def logreg(X_train, y_train, X_test, y_test):\n",
        "  text_classifier = LogisticRegression(solver='sag', C=10)\n",
        "  lr_pipeline = Pipeline([('clf', OneVsRestClassifier(text_classifier)),])\n",
        "  categories = list(y_train.columns.values)\n",
        "  print(categories)\n",
        "  y_pred = []\n",
        "  for category in categories:\n",
        "      print(category)\n",
        "      \n",
        "      # Training logistic regression model on train data\n",
        "      lr_pipeline.fit(X_train, y_train[category])\n",
        "      \n",
        "      # calculating test accuracy\n",
        "      predictions = lr_pipeline.predict(X_test)\n",
        "      y_pred.append(predictions)\n",
        "      print('Test accuracy is {}'.format(accuracy_score(y_true=y_test[category], y_pred=predictions)))\n",
        "      print(\"\\n\")\n",
        "\n",
        "      print('Test F1 score is {}'.format(f1_score(y_true=y_test[category], y_pred=predictions, average='weighted')))\n",
        "      print('\\n')\n",
        "\n",
        "      print('classification report per label')\n",
        "      print(classification_report(y_pred=predictions, y_true=y_test[category]))\n",
        "\n",
        "  return predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vFlJ1HU9GBZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f231f5d6-a666-4910-f26e-97a8cdf54b43"
      },
      "source": [
        "# classify validation data \n",
        "val_pred = logreg(vectorized_X_train_subset, y_train, vectorized_X_val, y_val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
            "**Processing toxic comments...**\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test accuracy is 0.91\n",
            "\n",
            "\n",
            "Test F1 score is 0.9033798882681563\n",
            "\n",
            "\n",
            "classification report per label\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.97      0.95       351\n",
            "           1       0.69      0.49      0.57        49\n",
            "\n",
            "    accuracy                           0.91       400\n",
            "   macro avg       0.81      0.73      0.76       400\n",
            "weighted avg       0.90      0.91      0.90       400\n",
            "\n",
            "**Processing severe_toxic comments...**\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test accuracy is 0.9775\n",
            "\n",
            "\n",
            "Test F1 score is 0.9744745938472174\n",
            "\n",
            "\n",
            "classification report per label\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.99      0.99       393\n",
            "           1       0.25      0.14      0.18         7\n",
            "\n",
            "    accuracy                           0.98       400\n",
            "   macro avg       0.62      0.57      0.59       400\n",
            "weighted avg       0.97      0.98      0.97       400\n",
            "\n",
            "**Processing obscene comments...**\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test accuracy is 0.9475\n",
            "\n",
            "\n",
            "Test F1 score is 0.9448817495973553\n",
            "\n",
            "\n",
            "classification report per label\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.98      0.97       374\n",
            "           1       0.62      0.50      0.55        26\n",
            "\n",
            "    accuracy                           0.95       400\n",
            "   macro avg       0.79      0.74      0.76       400\n",
            "weighted avg       0.94      0.95      0.94       400\n",
            "\n",
            "**Processing threat comments...**\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test accuracy is 1.0\n",
            "\n",
            "\n",
            "Test F1 score is 1.0\n",
            "\n",
            "\n",
            "classification report per label\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       399\n",
            "           1       1.00      1.00      1.00         1\n",
            "\n",
            "    accuracy                           1.00       400\n",
            "   macro avg       1.00      1.00      1.00       400\n",
            "weighted avg       1.00      1.00      1.00       400\n",
            "\n",
            "**Processing insult comments...**\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test accuracy is 0.955\n",
            "\n",
            "\n",
            "Test F1 score is 0.9541600000000001\n",
            "\n",
            "\n",
            "classification report per label\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.98      0.98       374\n",
            "           1       0.67      0.62      0.64        26\n",
            "\n",
            "    accuracy                           0.95       400\n",
            "   macro avg       0.82      0.80      0.81       400\n",
            "weighted avg       0.95      0.95      0.95       400\n",
            "\n",
            "**Processing identity_hate comments...**\n",
            "Test accuracy is 0.9875\n",
            "\n",
            "\n",
            "Test F1 score is 0.984845072959827\n",
            "\n",
            "\n",
            "classification report per label\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99       395\n",
            "           1       0.50      0.20      0.29         5\n",
            "\n",
            "    accuracy                           0.99       400\n",
            "   macro avg       0.74      0.60      0.64       400\n",
            "weighted avg       0.98      0.99      0.98       400\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qq9dzoUdLVeD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52a38b4d-85f9-4adf-81aa-b655e81d871c"
      },
      "source": [
        "# classify test data\n",
        "# this time don't split X_train into train and val sets\n",
        "vectorized_X_train = bert_vectorize(X_train_subset, model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total time to vectorize:  311.8511230945587\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5UzDxrIB14X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a49439c8-e99a-446d-e021-938a08caa462"
      },
      "source": [
        "y_pred = logreg(vectorized_X_train, y_train_subset, vectorized_X_test, y_test_subset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
            "**Processing toxic comments...**\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test accuracy is 0.9025\n",
            "\n",
            "\n",
            "Test F1 score is 0.9118474633650916\n",
            "\n",
            "\n",
            "classification report per label\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.92      0.95       366\n",
            "           1       0.45      0.71      0.55        34\n",
            "\n",
            "    accuracy                           0.90       400\n",
            "   macro avg       0.71      0.81      0.75       400\n",
            "weighted avg       0.93      0.90      0.91       400\n",
            "\n",
            "**Processing severe_toxic comments...**\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test accuracy is 0.9925\n",
            "\n",
            "\n",
            "Test F1 score is 0.9937452948557088\n",
            "\n",
            "\n",
            "classification report per label\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      1.00       399\n",
            "           1       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.99       400\n",
            "   macro avg       0.50      0.50      0.50       400\n",
            "weighted avg       0.99      0.99      0.99       400\n",
            "\n",
            "**Processing obscene comments...**\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test accuracy is 0.9375\n",
            "\n",
            "\n",
            "Test F1 score is 0.9318745350855443\n",
            "\n",
            "\n",
            "classification report per label\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.98      0.97       378\n",
            "           1       0.40      0.27      0.32        22\n",
            "\n",
            "    accuracy                           0.94       400\n",
            "   macro avg       0.68      0.62      0.65       400\n",
            "weighted avg       0.93      0.94      0.93       400\n",
            "\n",
            "**Processing threat comments...**\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test accuracy is 0.995\n",
            "\n",
            "\n",
            "Test F1 score is 0.995\n",
            "\n",
            "\n",
            "classification report per label\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       399\n",
            "           1       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.99       400\n",
            "   macro avg       0.50      0.50      0.50       400\n",
            "weighted avg       0.99      0.99      0.99       400\n",
            "\n",
            "**Processing insult comments...**\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test accuracy is 0.94\n",
            "\n",
            "\n",
            "Test F1 score is 0.9425685425685425\n",
            "\n",
            "\n",
            "classification report per label\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.96      0.97       380\n",
            "           1       0.42      0.50      0.45        20\n",
            "\n",
            "    accuracy                           0.94       400\n",
            "   macro avg       0.70      0.73      0.71       400\n",
            "weighted avg       0.95      0.94      0.94       400\n",
            "\n",
            "**Processing identity_hate comments...**\n",
            "Test accuracy is 0.985\n",
            "\n",
            "\n",
            "Test F1 score is 0.9800377833753149\n",
            "\n",
            "\n",
            "classification report per label\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99       395\n",
            "           1       0.00      0.00      0.00         5\n",
            "\n",
            "    accuracy                           0.98       400\n",
            "   macro avg       0.49      0.50      0.50       400\n",
            "weighted avg       0.98      0.98      0.98       400\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CU3OeEcG8VBn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69993bef-1bd2-48de-bf73-77ff614375ab"
      },
      "source": [
        "# convert y_pred to df with each category's predictions getting slotted into the corresponding column\n",
        "y_pred_df = pd.DataFrame(columns = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"])\n",
        "y_pred_df[\"toxic\"] = y_pred[0]\n",
        "y_pred_df[\"severe_toxic\"] = y_pred[1]\n",
        "y_pred_df[\"obscene\"] = y_pred[2]\n",
        "y_pred_df[\"threat\"] = y_pred[3]\n",
        "y_pred_df[\"insult\"] = y_pred[4]\n",
        "y_pred_df[\"identity_hate\"] = y_pred[5]\n",
        "print(y_pred_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     toxic  severe_toxic  obscene  threat  insult  identity_hate\n",
            "0        0             0        0       0       0              0\n",
            "1        1             0        0       0       0              0\n",
            "2        0             0        0       0       0              0\n",
            "3        0             0        0       0       0              0\n",
            "4        0             0        0       0       0              0\n",
            "..     ...           ...      ...     ...     ...            ...\n",
            "395      0             0        0       0       0              0\n",
            "396      0             0        0       0       0              0\n",
            "397      0             0        0       0       0              0\n",
            "398      0             0        0       0       0              0\n",
            "399      0             0        0       0       0              0\n",
            "\n",
            "[400 rows x 6 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-pi8YJ7tQ0Z3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46f99ec4-1919-49f4-d892-e6b6088bc58c"
      },
      "source": [
        "print(classification_report(y_pred=y_pred_df['toxic'], y_true=y_test_subset['toxic']))\n",
        "print(classification_report(y_pred=y_pred_df['severe_toxic'], y_true=y_test_subset['severe_toxic']))\n",
        "print(classification_report(y_pred=y_pred_df['obscene'], y_true=y_test_subset['obscene']))\n",
        "print(classification_report(y_pred=y_pred_df['threat'], y_true=y_test_subset['threat']))\n",
        "print(classification_report(y_pred=y_pred_df['insult'], y_true=y_test_subset['insult']))\n",
        "print(classification_report(y_pred=y_pred_df['identity_hate'], y_true=y_test_subset['identity_hate']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.92      0.95       366\n",
            "           1       0.45      0.71      0.55        34\n",
            "\n",
            "    accuracy                           0.90       400\n",
            "   macro avg       0.71      0.81      0.75       400\n",
            "weighted avg       0.93      0.90      0.91       400\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      1.00       399\n",
            "           1       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.99       400\n",
            "   macro avg       0.50      0.50      0.50       400\n",
            "weighted avg       0.99      0.99      0.99       400\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.98      0.97       378\n",
            "           1       0.40      0.27      0.32        22\n",
            "\n",
            "    accuracy                           0.94       400\n",
            "   macro avg       0.68      0.62      0.65       400\n",
            "weighted avg       0.93      0.94      0.93       400\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       399\n",
            "           1       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.99       400\n",
            "   macro avg       0.50      0.50      0.50       400\n",
            "weighted avg       0.99      0.99      0.99       400\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.96      0.97       380\n",
            "           1       0.42      0.50      0.45        20\n",
            "\n",
            "    accuracy                           0.94       400\n",
            "   macro avg       0.70      0.73      0.71       400\n",
            "weighted avg       0.95      0.94      0.94       400\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99       395\n",
            "           1       0.00      0.00      0.00         5\n",
            "\n",
            "    accuracy                           0.98       400\n",
            "   macro avg       0.49      0.50      0.50       400\n",
            "weighted avg       0.98      0.98      0.98       400\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xJtOrux-3cm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e3787f6-75bd-4acc-b6e6-88a836bb2b46"
      },
      "source": [
        "print(y_test_subset)\n",
        "print(roc_auc_score(y_true=y_test_subset[[\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]].values, y_score=y_pred_df[[\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]].values))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     toxic  severe_toxic  obscene  threat  insult  identity_hate\n",
            "5        0             0        0       0       0              0\n",
            "7        0             0        0       0       0              0\n",
            "11       0             0        0       0       0              0\n",
            "13       0             0        0       0       0              0\n",
            "14       0             0        0       0       0              0\n",
            "..     ...           ...      ...     ...     ...            ...\n",
            "931      0             0        0       0       0              0\n",
            "934      0             0        0       0       0              0\n",
            "935      0             0        0       0       0              0\n",
            "937      0             0        0       0       0              0\n",
            "939      0             0        0       0       0              0\n",
            "\n",
            "[400 rows x 6 columns]\n",
            "0.6107227151130059\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VnqnqZHp_Rsq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}